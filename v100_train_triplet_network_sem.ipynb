{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from utils.Param import get_default_param\n",
    "from utils.eval import fpr, retrieval_recall_K\n",
    "\n",
    "from network.model_fn import triplet_model_fn\n",
    "from network.dataset.sem_patchdata import input_fn\n",
    "from network.dataset.sem_patchdata_ext import input_fn as sem_input_fn\n",
    "from network.train import TripletEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproduction\n",
    "np.random.seed(2019)\n",
    "tf.set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters (adjust as needed)\n",
    "log_dir = './log/sem'\n",
    "param = get_default_param(mode='AUSTIN', log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param.data_dir = '/home/sungsooha/Desktop/Data/ftfy/austin'\n",
    "#param.data_dir = './Data/austin'\n",
    "param.train_datasets = 'sem' # we will define sem dataset separately\n",
    "param.test_datasets = None #'human_patch'\n",
    "param.batch_size = 8 # 64 for v100\n",
    "param.n_epoch = 100\n",
    "param.n_triplet_samples = 500000\n",
    "param.train_log_every   = 100000\n",
    "\n",
    "test_datasets = None #'scene_patch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_data_dir = '/home/sungsooha/Desktop/Data/ftfy/sem/train'\n",
    "sem_train_datasets = []\n",
    "for f in os.listdir(sem_data_dir):\n",
    "    if os.path.isdir(os.path.join(sem_data_dir,f)):\n",
    "        sem_train_datasets.append(f)\n",
    "sem_train_datasets = sorted(sem_train_datasets)\n",
    "print(sem_train_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info(\"Preparing data pipeline ...\")\n",
    "with tf.device('/cpu:0'), tf.name_scope('input'):\n",
    "    train_dataset, train_data_sampler = sem_input_fn(\n",
    "        data_dir=sem_data_dir,\n",
    "        base_patch_size=param.base_patch_size,\n",
    "        patches_per_row=10,\n",
    "        patches_per_col=10,\n",
    "        batch_size=param.batch_size,\n",
    "        patch_size=param.patch_size,\n",
    "        n_channels=param.n_channels\n",
    "    )\n",
    "    test_dataset, test_data_sampler = input_fn(\n",
    "        data_dir=param.data_dir,\n",
    "        base_patch_size=param.base_patch_size,\n",
    "        patches_per_row=param.patches_per_row,\n",
    "        patches_per_col=param.patches_per_col,\n",
    "        batch_size=param.batch_size,\n",
    "        patch_size=param.patch_size,\n",
    "        n_channels=param.n_channels\n",
    "    )\n",
    "    test_dataset_2, test_data_sampler_2 = input_fn(\n",
    "        data_dir=param.data_dir,\n",
    "        base_patch_size=param.base_patch_size,\n",
    "        patches_per_row=param.patches_per_row,\n",
    "        patches_per_col=param.patches_per_col,\n",
    "        batch_size=param.batch_size,\n",
    "        patch_size=param.patch_size,\n",
    "        n_channels=param.n_channels\n",
    "    )    \n",
    "    data_iterator = tf.data.Iterator.from_structure(\n",
    "        train_dataset.output_types,\n",
    "        train_dataset.output_shapes\n",
    "    )\n",
    "    train_dataset_init = data_iterator.make_initializer(train_dataset)\n",
    "    test_dataset_init = data_iterator.make_initializer(test_dataset)\n",
    "    test_dataset_init_2 = data_iterator.make_initializer(test_dataset_2)\n",
    "    batch_data = data_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sampler.load_dataset(\n",
    "    dir_name=sem_train_datasets,\n",
    "    ext='bmp',\n",
    "    patch_size=param.patch_size,\n",
    "    n_channels=param.n_channels,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if param.test_datasets is not None:\n",
    "    test_data_sampler.load_dataset(\n",
    "        dir_name=param.test_datasets,\n",
    "        ext='bmp',\n",
    "        patch_size=param.patch_size,\n",
    "        n_channels=param.n_channels,\n",
    "        debug=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_datasets is not None:\n",
    "    test_data_sampler_2.load_dataset(\n",
    "        dir_name=test_datasets,\n",
    "        ext='bmp',\n",
    "        patch_size=param.patch_size,\n",
    "        n_channels=param.n_channels,\n",
    "        debug=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info('Loading training stats: %s' % param.train_datasets)\n",
    "try:\n",
    "    file = open(os.path.join(param.log_dir, 'stats_%s.pkl' % param.train_datasets), 'rb')\n",
    "    mean, std = pickle.load(file)\n",
    "except:\n",
    "    tf.logging.info('Calculating train data stats (mean, std)')\n",
    "    mean, std = train_data_sampler.generate_stats()\n",
    "    pickle.dump(\n",
    "        [mean, std], \n",
    "        open(os.path.join(param.log_dir, 'stats_%s.pkl' % param.train_datasets), 'wb')\n",
    "    )\n",
    "tf.logging.info('Mean: {:.5f}'.format(mean))\n",
    "tf.logging.info('Std : {:.5f}'.format(std))\n",
    "train_data_sampler.normalize_data(mean, std)\n",
    "\n",
    "if param.test_datasets is not None:\n",
    "    test_data_sampler.normalize_data(mean, std)\n",
    "\n",
    "if test_datasets is not None:\n",
    "    test_data_sampler_2.normalize_data(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.info(\"Creating the model ...\")\n",
    "anchors, positives, negatives = batch_data\n",
    "spec = triplet_model_fn(\n",
    "    anchors, positives, negatives, n_feats=param.n_features,\n",
    "    mode='TRAIN', cnn_name=param.cnn_name, loss_name=param.loss_name,\n",
    "    optimizer_name=param.optimizer_name,\n",
    "    margin=param.margin,\n",
    "    use_regularization_loss=param.use_regularization,\n",
    "    learning_rate=param.learning_rate,\n",
    "    shared_batch_layers=True,\n",
    "    name='triplet-net'\n",
    ")\n",
    "estimator = TripletEstimator(spec, save_dir=param.log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=[1, 5, 10, 20, 30]\n",
    "\n",
    "all_loss = [] # avg. loss over epochs\n",
    "train_fpr95 = [] # fpr95 with training dataset\n",
    "train_retrieval = [] # retrieval with training dataset\n",
    "test_fpr95 = []\n",
    "test_retrieval = []\n",
    "test_fpr95_2 = []\n",
    "test_retrieval_2 = []\n",
    "\n",
    "tf.logging.info('='*50)\n",
    "tf.logging.info('Start training ...')\n",
    "tf.logging.info('='*50)\n",
    "for epoch in range(param.n_epoch):\n",
    "    tf.logging.info('-'*50)\n",
    "    tf.logging.info('TRAIN {:d}, {:s} start ...'.format(epoch, param.train_datasets))\n",
    "    train_data_sampler.set_mode(0)\n",
    "    #train_data_sampler.set_n_triplet_samples(param.n_triplet_samples)\n",
    "    train_data_sampler.set_n_triplet_samples(5000)\n",
    "    loss = estimator.train(\n",
    "        dataset_initializer=train_dataset_init,\n",
    "        log_every=param.train_log_every\n",
    "    )\n",
    "    all_loss.append(loss)\n",
    "    tf.logging.info('-'*50)\n",
    "\n",
    "    # for evaluation with training dataset\n",
    "    tf.logging.info('-'*50)\n",
    "    tf.logging.info('TEST {:d}, {:s} start ...'.format(epoch, param.train_datasets))\n",
    "    train_data_sampler.set_mode(1)\n",
    "    train_data_sampler.set_n_matched_pairs(5000)\n",
    "    test_match = estimator.run_match(train_dataset_init)\n",
    "    fpr95 = fpr(test_match.labels, test_match.scores, recall_rate=0.95)\n",
    "    train_fpr95.append(fpr95)\n",
    "    tf.logging.info('FPR95: {:.5f}'.format(fpr95))\n",
    "    \n",
    "    train_data_sampler.set_mode(2)\n",
    "    test_rrr = estimator.run_retrieval(train_dataset_init)\n",
    "    rrr = retrieval_recall_K(\n",
    "        features=test_rrr.features,\n",
    "        labels=train_data_sampler.get_labels(test_rrr.index),\n",
    "        is_query=test_rrr.scores,\n",
    "        K=K\n",
    "    )[0]\n",
    "    train_retrieval.append(rrr)\n",
    "    tf.logging.info('Retrieval: {}'.format(rrr))\n",
    "    tf.logging.info('-'*50)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    # for evaluation with test dataset\n",
    "    if param.test_datasets is not None:\n",
    "        tf.logging.info('-'*50)\n",
    "        tf.logging.info('TEST {:d}, {:s} start ...'.format(epoch, param.test_datasets))\n",
    "        test_data_sampler.set_mode(1)\n",
    "        #test_data_sampler.set_n_matched_pairs(1000)\n",
    "        test_match = estimator.run_match(test_dataset_init)\n",
    "        fpr95 = fpr(test_match.labels, test_match.scores, recall_rate=0.95)\n",
    "        test_fpr95.append(fpr95)\n",
    "        tf.logging.info('FPR95: {:.5f}'.format(fpr95))\n",
    "\n",
    "        test_data_sampler.set_mode(2)\n",
    "        test_rrr = estimator.run_retrieval(test_dataset_init)\n",
    "        rrr = retrieval_recall_K(\n",
    "            features=test_rrr.features,\n",
    "            labels=test_data_sampler.get_labels(test_rrr.index),\n",
    "            is_query=test_rrr.scores,\n",
    "            K=K\n",
    "        )[0]\n",
    "        test_retrieval.append(rrr)\n",
    "        tf.logging.info('Retrieval: {}'.format(rrr))\n",
    "        tf.logging.info('-'*50)\n",
    "    \n",
    "    # for evaluation with test dataset\n",
    "    if test_datasets is not None:\n",
    "        tf.logging.info('-'*50)\n",
    "        tf.logging.info('TEST {:d}, {:s} start ...'.format(epoch, test_datasets))\n",
    "        test_data_sampler_2.set_mode(1)\n",
    "        #test_data_sampler.set_n_matched_pairs(1000)\n",
    "        test_match = estimator.run_match(test_dataset_init_2)\n",
    "        fpr95 = fpr(test_match.labels, test_match.scores, recall_rate=0.95)\n",
    "        test_fpr95_2.append(fpr95)\n",
    "        tf.logging.info('FPR95: {:.5f}'.format(fpr95))\n",
    "\n",
    "        test_data_sampler_2.set_mode(2)\n",
    "        test_rrr = estimator.run_retrieval(test_dataset_init_2)\n",
    "        rrr = retrieval_recall_K(\n",
    "            features=test_rrr.features,\n",
    "            labels=test_data_sampler_2.get_labels(test_rrr.index),\n",
    "            is_query=test_rrr.scores,\n",
    "            K=K\n",
    "        )[0]\n",
    "        test_retrieval_2.append(rrr)\n",
    "        tf.logging.info('Retrieval: {}'.format(rrr))\n",
    "        tf.logging.info('-'*50)\n",
    "    \n",
    "    # save checkpoint\n",
    "    if epoch % param.save_every == 0 or epoch+1 == param.n_epoch:\n",
    "        estimator.save(param.project_name, global_step=epoch)\n",
    "    \n",
    "    #if epoch > 10:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].plot(train_fpr95)\n",
    "ax[1].plot(test_fpr95)\n",
    "ax[2].plot(test_fpr95_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].plot(train_retrieval)\n",
    "ax[1].plot(test_retrieval)\n",
    "ax[2].plot(test_retrieval_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "out_dir = os.path.join(param.log_dir, 'metrics_{}_{}.npy'.format(\n",
    "    param.train_datasets, param.train_datasets\n",
    "))\n",
    "metric = dict(\n",
    "    loss=np.array(all_loss),\n",
    "    fpr95=np.array(train_fpr95),\n",
    "    retrieval=np.asarray(train_retrieval)\n",
    ")\n",
    "np.save(out_dir, metric)\n",
    "\n",
    "out_dir = os.path.join(param.log_dir, 'metrics_{}_{}.npy'.format(\n",
    "    param.train_datasets, param.test_datasets\n",
    "))\n",
    "metric = dict(\n",
    "    loss=np.array(all_loss),\n",
    "    fpr95=np.array(test_fpr95),\n",
    "    retrieval=np.asarray(test_retrieval)\n",
    ")\n",
    "np.save(out_dir, metric)\n",
    "\n",
    "out_dir = os.path.join(param.log_dir, 'metrics_{}_{}.npy'.format(\n",
    "    param.train_datasets, test_datasets\n",
    "))\n",
    "metric = dict(\n",
    "    loss=np.array(all_loss),\n",
    "    fpr95=np.array(test_fpr95_2),\n",
    "    retrieval=np.asarray(test_retrieval_2)\n",
    ")\n",
    "np.save(out_dir, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
